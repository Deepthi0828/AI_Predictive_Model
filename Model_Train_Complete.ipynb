{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "178822c0-7a6c-4b3c-aaf8-c963d612f388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equipment Failure Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Equipment ID      1000 non-null   object\n",
      " 1   Failure Date      1000 non-null   object\n",
      " 2   Type              1000 non-null   object\n",
      " 3   Maintenance Date  1000 non-null   object\n",
      " 4   Failure Cause     1000 non-null   object\n",
      " 5   Risk Level        1000 non-null   object\n",
      " 6   Severity          1000 non-null   int64 \n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 54.8+ KB\n",
      "None\n",
      "  Equipment ID Failure Date                Type Maintenance Date  \\\n",
      "0       E-0001   2022-08-06       Conveyor Belt       2023-07-31   \n",
      "1       E-0002   2023-03-14         Pump System       2023-01-31   \n",
      "2       E-0003   2024-06-03  Ventilation System       2023-05-04   \n",
      "3       E-0004   2024-04-24    Drilling Machine       2021-12-02   \n",
      "4       E-0005   2023-02-13  Ventilation System       2021-07-03   \n",
      "\n",
      "      Failure Cause Risk Level  Severity  \n",
      "0      Improper Use       High         8  \n",
      "1       Wear & Tear       High         8  \n",
      "2  Electrical Fault     Medium         6  \n",
      "3  Electrical Fault        Low         3  \n",
      "4           Unknown       High         8  \n",
      "\n",
      "Historical Data Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Incident ID         1000 non-null   object\n",
      " 1   Date                1000 non-null   object\n",
      " 2   Location            1000 non-null   object\n",
      " 3   Hazard Type         1000 non-null   object\n",
      " 4   Severity            1000 non-null   int64 \n",
      " 5   Cause               1000 non-null   object\n",
      " 6   Failure Cause       1000 non-null   object\n",
      " 7   Equipment Type      1000 non-null   object\n",
      " 8   Risk Level          1000 non-null   object\n",
      " 9   Recommended Action  1000 non-null   object\n",
      " 10  Outcome             1000 non-null   object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 86.1+ KB\n",
      "None\n",
      "  Incident ID        Date  Location          Hazard Type  Severity  \\\n",
      "0      I-0001  2024-03-30  Sector A        Gas Explosion         7   \n",
      "1      I-0002  2021-12-10  Sector A        Gas Explosion         4   \n",
      "2      I-0003  2024-06-16  Sector A        Gas Explosion         8   \n",
      "3      I-0004  2023-07-15  Sector D    Equipment Failure         3   \n",
      "4      I-0005  2022-08-24  Sector A  Structural Collapse         8   \n",
      "\n",
      "                 Cause     Failure Cause      Equipment Type Risk Level  \\\n",
      "0     High Temperature  Electrical Fault  Ventilation System     Medium   \n",
      "1              Unknown      Improper Use    Drilling Machine       High   \n",
      "2     High Temperature          Overload    Drilling Machine     Medium   \n",
      "3  Maintenance Neglect          Overload       Conveyor Belt        Low   \n",
      "4  Maintenance Neglect      Improper Use    Drilling Machine   Critical   \n",
      "\n",
      "    Recommended Action         Outcome  \n",
      "0  Improve Ventilation   No Casualties  \n",
      "1  Improve Ventilation   No Casualties  \n",
      "2    Inspect Equipment  Major Injuries  \n",
      "3        Evacuate Area   No Casualties  \n",
      "4     Enhance Training      1 Fatality  \n",
      "\n",
      "Miner Hazard Reports Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Report ID    1000 non-null   object\n",
      " 1   Timestamp    1000 non-null   object\n",
      " 2   Miner ID     1000 non-null   object\n",
      " 3   Hazard Type  1000 non-null   object\n",
      " 4   Location     1000 non-null   object\n",
      " 5   Severity     1000 non-null   int64 \n",
      " 6   Description  1000 non-null   object\n",
      " 7   Risk Level   1000 non-null   object\n",
      " 8   Cause        1000 non-null   object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 70.4+ KB\n",
      "None\n",
      "  Report ID            Timestamp Miner ID             Hazard Type  Location  \\\n",
      "0    R-0001  2024-04-01 02:50:20   M-0405               Fire Risk  Sector D   \n",
      "1    R-0002  2024-04-23 15:55:31   M-0018  Structural Instability  Sector D   \n",
      "2    R-0003  2024-11-17 03:56:36   M-0141               Fire Risk  Sector C   \n",
      "3    R-0004  2024-03-15 15:28:12   M-0444   Equipment Malfunction  Sector A   \n",
      "4    R-0005  2024-10-31 17:38:12   M-0042  Structural Instability  Sector D   \n",
      "\n",
      "   Severity                       Description Risk Level                Cause  \n",
      "0         7     Equipment making loud noises.       High    Equipment Failure  \n",
      "1         8  High temperature near equipment.       High    Equipment Failure  \n",
      "2         9       Detected unusual gas smell.   Critical        Gas Explosion  \n",
      "3         5  Noticed cracks in the structure.     Medium  Structural Collapse  \n",
      "4        10     Equipment making loud noises.   Critical    Equipment Failure  \n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "historical_data = pd.read_csv('/Users/deepu/Desktop/Mini_Project/Datasets/historical_data.csv')\n",
    "equipment_failure = pd.read_csv('/Users/deepu/Desktop/Mini_Project/Datasets/equipment_failure.csv')\n",
    "minor_hazard_rep = pd.read_csv('/Users/deepu/Desktop/Mini_Project/Datasets/minor_hazard_rep.csv')\n",
    "\n",
    "# Display basic information about each dataset\n",
    "print(\"Equipment Failure Dataset Info:\")\n",
    "print(equipment_failure.info())\n",
    "print(equipment_failure.head())\n",
    "\n",
    "print(\"\\nHistorical Data Dataset Info:\")\n",
    "print(historical_data.info())\n",
    "print(historical_data.head())\n",
    "\n",
    "print(\"\\nMiner Hazard Reports Dataset Info:\")\n",
    "print(minor_hazard_rep.info())\n",
    "print(minor_hazard_rep.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a50180dd-5be6-43ce-a4ed-b90316eccdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equipment Failure Dataset Missing Values:\n",
      " Equipment ID        0\n",
      "Failure Date        0\n",
      "Type                0\n",
      "Maintenance Date    0\n",
      "Failure Cause       0\n",
      "Risk Level          0\n",
      "Severity            0\n",
      "dtype: int64\n",
      "Historical Data Dataset Missing Values:\n",
      " Incident ID           0\n",
      "Date                  0\n",
      "Location              0\n",
      "Hazard Type           0\n",
      "Severity              0\n",
      "Cause                 0\n",
      "Failure Cause         0\n",
      "Equipment Type        0\n",
      "Risk Level            0\n",
      "Recommended Action    0\n",
      "Outcome               0\n",
      "dtype: int64\n",
      "Miner Hazard Reports Dataset Missing Values:\n",
      " Report ID      0\n",
      "Timestamp      0\n",
      "Miner ID       0\n",
      "Hazard Type    0\n",
      "Location       0\n",
      "Severity       0\n",
      "Description    0\n",
      "Risk Level     0\n",
      "Cause          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "# Drop rows with missing values in all datasets\n",
    "equipment_failure_cleaned = equipment_failure.dropna()\n",
    "historical_data_cleaned = historical_data.dropna()\n",
    "minor_hazard_rep_cleaned = minor_hazard_rep.dropna()\n",
    "\n",
    "# Check for missing values after cleaning\n",
    "print(\"Equipment Failure Dataset Missing Values:\\n\", equipment_failure_cleaned.isnull().sum())\n",
    "print(\"Historical Data Dataset Missing Values:\\n\", historical_data_cleaned.isnull().sum())\n",
    "print(\"Miner Hazard Reports Dataset Missing Values:\\n\", minor_hazard_rep_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "466e0f4d-1ab2-43f4-919c-3ea79b8a8682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Equipment Failure Dataset:\n",
      "   Equipment ID Failure Date                Type Maintenance Date  \\\n",
      "0       E-0001   2022-08-06       Conveyor Belt       2023-07-31   \n",
      "1       E-0002   2023-03-14         Pump System       2023-01-31   \n",
      "2       E-0003   2024-06-03  Ventilation System       2023-05-04   \n",
      "3       E-0004   2024-04-24    Drilling Machine       2021-12-02   \n",
      "4       E-0005   2023-02-13  Ventilation System       2021-07-03   \n",
      "\n",
      "      Failure Cause Risk Level  Severity  \n",
      "0      Improper Use       High  0.475344  \n",
      "1       Wear & Tear       High  0.475344  \n",
      "2  Electrical Fault     Medium -0.289490  \n",
      "3  Electrical Fault        Low -1.436740  \n",
      "4           Unknown       High  0.475344  \n",
      "\n",
      "Normalized Historical Data Dataset:\n",
      "   Incident ID        Date  Location          Hazard Type  Severity  \\\n",
      "0      I-0001  2024-03-30  Sector A        Gas Explosion  0.531053   \n",
      "1      I-0002  2021-12-10  Sector A        Gas Explosion -0.517768   \n",
      "2      I-0003  2024-06-16  Sector A        Gas Explosion  0.880659   \n",
      "3      I-0004  2023-07-15  Sector D    Equipment Failure -0.867374   \n",
      "4      I-0005  2022-08-24  Sector A  Structural Collapse  0.880659   \n",
      "\n",
      "                 Cause     Failure Cause      Equipment Type Risk Level  \\\n",
      "0     High Temperature  Electrical Fault  Ventilation System     Medium   \n",
      "1              Unknown      Improper Use    Drilling Machine       High   \n",
      "2     High Temperature          Overload    Drilling Machine     Medium   \n",
      "3  Maintenance Neglect          Overload       Conveyor Belt        Low   \n",
      "4  Maintenance Neglect      Improper Use    Drilling Machine   Critical   \n",
      "\n",
      "    Recommended Action         Outcome  \n",
      "0  Improve Ventilation   No Casualties  \n",
      "1  Improve Ventilation   No Casualties  \n",
      "2    Inspect Equipment  Major Injuries  \n",
      "3        Evacuate Area   No Casualties  \n",
      "4     Enhance Training      1 Fatality  \n",
      "\n",
      "Normalized Miner Hazard Reports Dataset:\n",
      "   Report ID            Timestamp Miner ID             Hazard Type  Location  \\\n",
      "0    R-0001  2024-04-01 02:50:20   M-0405               Fire Risk  Sector D   \n",
      "1    R-0002  2024-04-23 15:55:31   M-0018  Structural Instability  Sector D   \n",
      "2    R-0003  2024-11-17 03:56:36   M-0141               Fire Risk  Sector C   \n",
      "3    R-0004  2024-03-15 15:28:12   M-0444   Equipment Malfunction  Sector A   \n",
      "4    R-0005  2024-10-31 17:38:12   M-0042  Structural Instability  Sector D   \n",
      "\n",
      "   Severity                       Description Risk Level                Cause  \n",
      "0  0.576708     Equipment making loud noises.       High    Equipment Failure  \n",
      "1  0.929003  High temperature near equipment.       High    Equipment Failure  \n",
      "2  1.281299       Detected unusual gas smell.   Critical        Gas Explosion  \n",
      "3 -0.127883  Noticed cracks in the structure.     Medium  Structural Collapse  \n",
      "4  1.633594     Equipment making loud noises.   Critical    Equipment Failure  \n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalize the Severity columns\n",
    "equipment_failure_cleaned['Severity'] = scaler.fit_transform(equipment_failure_cleaned[['Severity']])\n",
    "historical_data_cleaned['Severity'] = scaler.fit_transform(historical_data_cleaned[['Severity']])\n",
    "minor_hazard_rep_cleaned['Severity'] = scaler.fit_transform(minor_hazard_rep_cleaned[['Severity']])\n",
    "\n",
    "# Check normalized data\n",
    "print(\"Normalized Equipment Failure Dataset:\\n\", equipment_failure_cleaned.head())\n",
    "print(\"\\nNormalized Historical Data Dataset:\\n\", historical_data_cleaned.head())\n",
    "print(\"\\nNormalized Miner Hazard Reports Dataset:\\n\", minor_hazard_rep_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18b71d6d-be52-47de-81c6-09e1506cba68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equipment Failure Dataset After Outlier Removal:\n",
      "            Severity\n",
      "count  1.000000e+03\n",
      "mean   1.065814e-16\n",
      "std    1.000500e+00\n",
      "min   -1.436740e+00\n",
      "25%   -1.436740e+00\n",
      "50%    4.753441e-01\n",
      "75%    1.240178e+00\n",
      "max    1.240178e+00\n",
      "\n",
      "Historical Data Dataset After Outlier Removal:\n",
      "            Severity\n",
      "count  1.000000e+03\n",
      "mean   3.286260e-17\n",
      "std    1.000500e+00\n",
      "min   -1.566588e+00\n",
      "25%   -8.673744e-01\n",
      "50%   -1.681609e-01\n",
      "75%    8.806595e-01\n",
      "max    1.579873e+00\n",
      "\n",
      "Miner Hazard Reports Dataset After Outlier Removal:\n",
      "            Severity\n",
      "count  1.000000e+03\n",
      "mean  -1.412204e-16\n",
      "std    1.000500e+00\n",
      "min   -1.537065e+00\n",
      "25%   -8.324743e-01\n",
      "50%   -1.278833e-01\n",
      "75%    9.290032e-01\n",
      "max    1.633594e+00\n"
     ]
    }
   ],
   "source": [
    "#4 \n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Remove outliers from the Severity columns\n",
    "equipment_failure_cleaned = remove_outliers(equipment_failure_cleaned, 'Severity')\n",
    "historical_data_cleaned = remove_outliers(historical_data_cleaned, 'Severity')\n",
    "minor_hazard_rep_cleaned = remove_outliers(minor_hazard_rep_cleaned, 'Severity')\n",
    "\n",
    "# Check datasets after outlier removal\n",
    "print(\"Equipment Failure Dataset After Outlier Removal:\\n\", equipment_failure_cleaned.describe())\n",
    "print(\"\\nHistorical Data Dataset After Outlier Removal:\\n\", historical_data_cleaned.describe())\n",
    "print(\"\\nMiner Hazard Reports Dataset After Outlier Removal:\\n\", minor_hazard_rep_cleaned.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fb758379-3296-4787-b7dc-a12e57a342f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Miner Hazard Reports Dataset:\n",
      "   Report ID            Timestamp Miner ID             Hazard Type  Location  \\\n",
      "0    R-0001  2024-04-01 02:50:20   M-0405               Fire Risk  Sector D   \n",
      "1    R-0002  2024-04-23 15:55:31   M-0018  Structural Instability  Sector D   \n",
      "2    R-0003  2024-11-17 03:56:36   M-0141               Fire Risk  Sector C   \n",
      "3    R-0004  2024-03-15 15:28:12   M-0444   Equipment Malfunction  Sector A   \n",
      "4    R-0005  2024-10-31 17:38:12   M-0042  Structural Instability  Sector D   \n",
      "\n",
      "   Severity                       Description Risk Level                Cause  \n",
      "0  0.576708     Equipment making loud noises.       High    Equipment Failure  \n",
      "1  0.929003  High temperature near equipment.       High    Equipment Failure  \n",
      "2  1.281299       Detected unusual gas smell.   Critical        Gas Explosion  \n",
      "3 -0.127883  Noticed cracks in the structure.     Medium  Structural Collapse  \n",
      "4  1.633594     Equipment making loud noises.   Critical    Equipment Failure  \n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the miner hazard report dataset\n",
    "miner_hazard_rep = pd.read_csv('/Users/deepu/Desktop/Mini_Project/Datasets/minor_hazard_rep.csv')\n",
    "\n",
    "# Clean the dataset: drop missing values and normalize Severity\n",
    "miner_hazard_rep_cleaned = miner_hazard_rep.dropna()\n",
    "\n",
    "# Normalize the Severity column\n",
    "scaler = StandardScaler()\n",
    "miner_hazard_rep_cleaned['Severity'] = scaler.fit_transform(miner_hazard_rep_cleaned[['Severity']])\n",
    "\n",
    "# Check the cleaned dataset\n",
    "print(\"Cleaned Miner Hazard Reports Dataset:\\n\", miner_hazard_rep_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a691ce7-7875-4294-a9bd-c64265dbac65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoders saved successfully!\n",
      "Miner Dataset Targets (Hazard Types):\n",
      " [1 3 1 0 3]\n",
      "\n",
      "Miner Dataset Targets (Causes):\n",
      " [0 0 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Features for miner reports\n",
    "miner_features = miner_hazard_rep_cleaned[['Severity', 'Cause', 'Location', 'Hazard Type']]\n",
    "miner_target_hazard = miner_hazard_rep_cleaned['Hazard Type']\n",
    "miner_target_cause = miner_hazard_rep_cleaned['Cause']\n",
    "\n",
    "# Encode targets\n",
    "label_encoder_hazard = LabelEncoder()\n",
    "label_encoder_cause = LabelEncoder()\n",
    "\n",
    "miner_target_hazard_encoded = label_encoder_hazard.fit_transform(miner_target_hazard)\n",
    "miner_target_cause_encoded = label_encoder_cause.fit_transform(miner_target_cause)\n",
    "\n",
    "# Save the label encoders for reuse\n",
    "joblib.dump(label_encoder_hazard, '/Users/deepu/Desktop/Mini_Project/label_encoder_hazard.pkl')\n",
    "joblib.dump(label_encoder_cause, '/Users/deepu/Desktop/Mini_Project/label_encoder_cause.pkl')\n",
    "print(\"Label encoders saved successfully!\")\n",
    "\n",
    "# Display Encoded Targets\n",
    "print(\"Miner Dataset Targets (Hazard Types):\\n\", miner_target_hazard_encoded[:5])\n",
    "print(\"\\nMiner Dataset Targets (Causes):\\n\", miner_target_cause_encoded[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb6d82e7-5e34-487c-8bbd-5784b1e0028d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded 'Failure Cause': [2 5 1 1 4]\n"
     ]
    }
   ],
   "source": [
    "# Equipment Failure Data\n",
    "equipment_features = equipment_failure_cleaned[['Severity', 'Risk Level']]\n",
    "\n",
    "# Use 'Failure Cause' as the target column\n",
    "if 'Failure Cause' in equipment_failure_cleaned.columns:\n",
    "    equipment_target_cause = equipment_failure_cleaned['Failure Cause']\n",
    "    # Encode the target\n",
    "    equipment_target_cause_encoded = label_encoder_cause.fit_transform(equipment_target_cause)\n",
    "else:\n",
    "    print(\"Warning: 'Failure Cause' column not found in equipment_failure_cleaned. Assigning placeholders.\")\n",
    "    equipment_target_cause_encoded = np.zeros(len(equipment_features), dtype=int)  # Placeholder for missing targets\n",
    "\n",
    "# Verify encoded target\n",
    "print(\"Encoded 'Failure Cause':\", equipment_target_cause_encoded[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c07d454-dcc1-4898-9f54-ab60eb29116d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in Miner Hazard Reports Dataset:\n",
      " Index(['Report ID', 'Timestamp', 'Miner ID', 'Hazard Type', 'Location',\n",
      "       'Severity', 'Description', 'Risk Level', 'Cause'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in Miner Hazard Reports Dataset:\\n\", miner_hazard_rep_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4113548e-5f7b-491d-826b-412cc955608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean the equipment failure dataset\n",
    "equipment_failure = pd.read_csv('/Users/deepu/Desktop/Mini_Project/Datasets/equipment_failure.csv')\n",
    "\n",
    "# Drop missing values\n",
    "equipment_failure_cleaned = equipment_failure.dropna()\n",
    "\n",
    "# Select features for training\n",
    "equipment_features = equipment_failure_cleaned[['Risk Level', 'Severity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "366a0412-0c4a-44b9-ae4c-c1551b8c75bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features DataFrame created successfully.\n",
      "   Severity  Location\n",
      "0  0.531053  Sector A\n",
      "1 -0.517768  Sector A\n",
      "2  0.880659  Sector A\n",
      "3 -0.867374  Sector D\n",
      "4  0.880659  Sector A\n",
      "Severity    float64\n",
      "Location     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Extract features from each cleaned dataset\n",
    "historical_features = historical_data_cleaned[['Severity', 'Location']].rename(columns={'Severity': 'Severity'})\n",
    "miner_features = miner_hazard_rep_cleaned[['Severity', 'Location']]\n",
    "equipment_features = equipment_failure_cleaned[['Severity', 'Risk Level']].rename(columns={'Risk Level': 'Location'})\n",
    "\n",
    "# Combine aligned features into a single DataFrame\n",
    "try:\n",
    "    features = pd.concat([historical_features, miner_features, equipment_features], axis=0).reset_index(drop=True)\n",
    "    print(\"Features DataFrame created successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error while creating features DataFrame:\", e)\n",
    "\n",
    "# Check the combined features\n",
    "print(features.head())\n",
    "print(features.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3fbaa4e9-8005-4671-b5fc-56bcba55485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity    float64\n",
      "Location     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of features\n",
    "print(features.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b4b6ddd-538b-45fb-907f-397fbeb76a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while creating features DataFrame: \"['Severity (1-10)'] not in index\"\n",
      "Severity    float64\n",
      "Location     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Ensure features are properly combined\n",
    "try:\n",
    "    features = pd.concat([\n",
    "        historical_features[['Severity (1-10)', 'Location']].rename(columns={'Severity (1-10)': 'Severity'}),\n",
    "        miner_features[['Severity', 'Location']],\n",
    "        equipment_features[['Severity', 'Risk Level']]\n",
    "    ], axis=0).reset_index(drop=True)\n",
    "\n",
    "    print(\"Features DataFrame created successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error while creating features DataFrame:\", e)\n",
    "\n",
    "# Check the data types of features\n",
    "if 'features' in locals():\n",
    "    print(features.dtypes)\n",
    "else:\n",
    "    print(\"Features DataFrame is not defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e8da0c84-34cc-4b87-834c-d2db2cb5c366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'Risk Level' column not found in equipment_features.\n",
      "Columns available in equipment_features: Index(['Severity', 'Location'], dtype='object')\n",
      "Columns after handling 'Risk Level': Index(['Severity', 'Location', 'Risk Level'], dtype='object')\n",
      "   Severity  Location Risk Level\n",
      "0  0.531053  Sector A        NaN\n",
      "1 -0.517768  Sector A        NaN\n",
      "2  0.880659  Sector A        NaN\n",
      "3 -0.867374  Sector D        NaN\n",
      "4  0.880659  Sector A        NaN\n",
      "Severity         0\n",
      "Location      1000\n",
      "Risk Level    2000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check columns in `equipment_features` to verify if 'Risk Level' exists\n",
    "if 'Risk Level' not in equipment_features.columns:\n",
    "    print(\"Error: 'Risk Level' column not found in equipment_features.\")\n",
    "    print(\"Columns available in equipment_features:\", equipment_features.columns)\n",
    "    \n",
    "    # Step 2: If 'Risk Level' is missing, you may either rename or add a placeholder column\n",
    "    # Option 1: Rename if there is a different column name or typo\n",
    "    # equipment_features = equipment_features.rename(columns={'incorrect_column_name': 'Risk Level'})\n",
    "    \n",
    "    # Option 2: Add a placeholder if 'Risk Level' should exist but is missing\n",
    "    equipment_features['Risk Level'] = 'Unknown'  # or some default value\n",
    "\n",
    "# Step 3: Verify column names after possible renaming or adding the 'Risk Level' column\n",
    "print(\"Columns after handling 'Risk Level':\", equipment_features.columns)\n",
    "\n",
    "# Step 4: Concatenate the DataFrames (historical_features, miner_features, and equipment_features)\n",
    "features = pd.concat([\n",
    "    historical_features[['Severity', 'Location']].rename(columns={'Severity (1-10)': 'Severity'}),\n",
    "    miner_features[['Severity', 'Location']],\n",
    "    equipment_features[['Severity', 'Risk Level']]  # Ensure 'Risk Level' exists\n",
    "], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Step 5: Check the concatenated DataFrame\n",
    "print(features.head())\n",
    "\n",
    "# Step 6: Optionally, inspect for any missing values or inconsistencies\n",
    "print(features.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fae329d8-daa5-48d6-86b9-1905a0cb56a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded 'Risk Level' and 'Location':\n",
      "    Risk Level  Location\n",
      "0           1         0\n",
      "1           1         0\n",
      "2           1         0\n",
      "3           1         3\n",
      "4           1         0\n"
     ]
    }
   ],
   "source": [
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the 'Risk Level' column\n",
    "features['Risk Level'] = label_encoder.fit_transform(features['Risk Level'])\n",
    "\n",
    "# Encode the 'Location' column\n",
    "features['Location'] = label_encoder.fit_transform(features['Location'])\n",
    "\n",
    "# Verify the output\n",
    "print(\"Encoded 'Risk Level' and 'Location':\\n\", features[['Risk Level', 'Location']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a47ddb2c-966c-470a-85e9-17a8bfe003a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity      float64\n",
      "Location        int64\n",
      "Risk Level      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(features.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9b0e719f-12cf-4572-8233-4a8793c6462d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features DataFrame Columns: Index(['Severity', 'Location', 'Risk Level'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Features DataFrame Columns:\", features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5a3dab47-3d77-481f-a3a3-b6536dfc2322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "historical_data = pd.read_csv('/Users/deepu/Desktop/Mini_Project/Datasets/historical_data.csv')\n",
    "equipment_failure = pd.read_csv('/Users/deepu/Desktop/Mini_Project/Datasets/equipment_failure.csv')\n",
    "minor_hazard_rep = pd.read_csv('/Users/deepu/Desktop/Mini_Project/Datasets/minor_hazard_rep.csv')\n",
    "\n",
    "\n",
    "# Combine data (example approach, replace with your actual logic)\n",
    "combined_data = pd.concat([equipment_failure, historical_data, minor_hazard_rep], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c1c5f3d8-fde4-4adb-a508-8510a8524d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Equipment ID Failure Date                Type Maintenance Date  \\\n",
      "0       E-0001   2022-08-06       Conveyor Belt       2023-07-31   \n",
      "1       E-0002   2023-03-14         Pump System       2023-01-31   \n",
      "2       E-0003   2024-06-03  Ventilation System       2023-05-04   \n",
      "3       E-0004   2024-04-24    Drilling Machine       2021-12-02   \n",
      "4       E-0005   2023-02-13  Ventilation System       2021-07-03   \n",
      "\n",
      "      Failure Cause Risk Level  Severity Incident ID Date Location  \\\n",
      "0      Improper Use       High         8         NaN  NaN      NaN   \n",
      "1       Wear & Tear       High         8         NaN  NaN      NaN   \n",
      "2  Electrical Fault     Medium         6         NaN  NaN      NaN   \n",
      "3  Electrical Fault        Low         3         NaN  NaN      NaN   \n",
      "4           Unknown       High         8         NaN  NaN      NaN   \n",
      "\n",
      "  Hazard Type Cause Equipment Type Recommended Action Outcome Report ID  \\\n",
      "0         NaN   NaN            NaN                NaN     NaN       NaN   \n",
      "1         NaN   NaN            NaN                NaN     NaN       NaN   \n",
      "2         NaN   NaN            NaN                NaN     NaN       NaN   \n",
      "3         NaN   NaN            NaN                NaN     NaN       NaN   \n",
      "4         NaN   NaN            NaN                NaN     NaN       NaN   \n",
      "\n",
      "  Timestamp Miner ID Description  \n",
      "0       NaN      NaN         NaN  \n",
      "1       NaN      NaN         NaN  \n",
      "2       NaN      NaN         NaN  \n",
      "3       NaN      NaN         NaN  \n",
      "4       NaN      NaN         NaN  \n",
      "Index(['Equipment ID', 'Failure Date', 'Type', 'Maintenance Date',\n",
      "       'Failure Cause', 'Risk Level', 'Severity', 'Incident ID', 'Date',\n",
      "       'Location', 'Hazard Type', 'Cause', 'Equipment Type',\n",
      "       'Recommended Action', 'Outcome', 'Report ID', 'Timestamp', 'Miner ID',\n",
      "       'Description'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(combined_data.head())\n",
    "print(combined_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a574008e-ae4f-4b41-bbb8-11823a6b8448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Columns: Index(['Equipment ID', 'Failure Date', 'Type', 'Maintenance Date',\n",
      "       'Failure Cause', 'Risk Level', 'Severity', 'Incident ID', 'Date',\n",
      "       'Location', 'Hazard Type', 'Cause', 'Equipment Type',\n",
      "       'Recommended Action', 'Outcome', 'Report ID', 'Timestamp', 'Miner ID',\n",
      "       'Description'],\n",
      "      dtype='object')\n",
      "Features shape: (3000, 2)\n",
      "Hazard Target shape: (3000,)\n",
      "Cause Target shape: (3000,)\n",
      "X_train_hazard shape: (2400, 2)\n",
      "X_test_hazard shape: (600, 2)\n",
      "y_train_hazard shape: (2400,)\n",
      "y_test_hazard shape: (600,)\n",
      "X_train_cause shape: (2400, 2)\n",
      "X_test_cause shape: (600, 2)\n",
      "y_train_cause shape: (2400,)\n",
      "y_test_cause shape: (600,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Check the dataset columns\n",
    "print(\"Dataset Columns:\", combined_data.columns)\n",
    "\n",
    "# Step 2: Extract features and targets\n",
    "# Replace 'Hazard' with 'Hazard Type' based on your dataset structure\n",
    "hazard_target = combined_data['Hazard Type']  # Target variable for hazard prediction\n",
    "cause_target = combined_data['Cause']         # Target variable for cause prediction\n",
    "features = combined_data[['Risk Level', 'Location']]  # Input feature columns\n",
    "\n",
    "# Step 3: Verify shapes\n",
    "print(\"Features shape:\", features.shape)\n",
    "print(\"Hazard Target shape:\", hazard_target.shape)\n",
    "print(\"Cause Target shape:\", cause_target.shape)\n",
    "\n",
    "# Step 4: Train-test split\n",
    "# Split for hazard prediction\n",
    "X_train_hazard, X_test_hazard, y_train_hazard, y_test_hazard = train_test_split(\n",
    "    features, hazard_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split for cause prediction\n",
    "X_train_cause, X_test_cause, y_train_cause, y_test_cause = train_test_split(\n",
    "    features, cause_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 5: Verify split sizes\n",
    "print(\"X_train_hazard shape:\", X_train_hazard.shape)\n",
    "print(\"X_test_hazard shape:\", X_test_hazard.shape)\n",
    "print(\"y_train_hazard shape:\", y_train_hazard.shape)\n",
    "print(\"y_test_hazard shape:\", y_test_hazard.shape)\n",
    "\n",
    "print(\"X_train_cause shape:\", X_train_cause.shape)\n",
    "print(\"X_test_cause shape:\", X_test_cause.shape)\n",
    "print(\"y_train_cause shape:\", y_train_cause.shape)\n",
    "print(\"y_test_cause shape:\", y_test_cause.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "64113bc5-7a2d-4757-8793-8d20e486aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest models for both tasks\n",
    "model_hazard = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "model_cause = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e8a57257-b372-45c9-ac58-0e9d1c516724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Risk Level': ['High' 'Medium' 'Low' 'Critical']\n",
      "Unique values in 'Location': [nan 'Sector A' 'Sector D' 'Sector C' 'Sector B']\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in 'Risk Level' and 'Location' to understand the mix of data types\n",
    "print(\"Unique values in 'Risk Level':\", features['Risk Level'].unique())\n",
    "print(\"Unique values in 'Location':\", features['Location'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9fd54b11-9732-4fce-bfde-5c4fb963191f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in features:\n",
      "Risk Level       0\n",
      "Location      1000\n",
      "dtype: int64\n",
      "NaN in hazard_target:\n",
      "1000\n",
      "NaN in cause_target:\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"NaN in features:\")\n",
    "print(features.isnull().sum())  # Check features for NaN\n",
    "\n",
    "print(\"NaN in hazard_target:\")\n",
    "print(hazard_target.isnull().sum())  # Check hazard_target for NaN\n",
    "\n",
    "print(\"NaN in cause_target:\")\n",
    "print(cause_target.isnull().sum())  # Check cause_target for NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9951de05-b4b8-46c6-98ee-201aedc6d29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in hazard_target_cleaned: 0\n",
      "NaN in cause_target_cleaned: 0\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with NaN in hazard_target\n",
    "mask_hazard = ~hazard_target.isnull()\n",
    "features_hazard = features[mask_hazard]\n",
    "hazard_target_cleaned = hazard_target[mask_hazard]\n",
    "\n",
    "# Remove rows with NaN in cause_target\n",
    "mask_cause = ~cause_target.isnull()\n",
    "features_cause = features[mask_cause]\n",
    "cause_target_cleaned = cause_target[mask_cause]\n",
    "\n",
    "# Ensure no NaN values remain\n",
    "print(\"NaN in hazard_target_cleaned:\", hazard_target_cleaned.isnull().sum())\n",
    "print(\"NaN in cause_target_cleaned:\", cause_target_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8e1aad71-2e5b-4c7c-a418-175b52a522eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cause_prediction_model.pkl']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming model_hazard and model_cause are your trained models\n",
    "  # Save hazard prediction model\n",
    "joblib.dump(model_cause, 'cause_prediction_model.pkl')    # Save cause prediction model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f01d9584-01d0-4c6c-b041-d3431ddbe0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hazard_prediction_model.pkl']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_hazard, 'hazard_prediction_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f93c447b-2349-4471-8689-02a82da10bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models trained and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model_hazard, '/Users/deepu/Desktop/Mini_Project/hazard_prediction_model.pkl')\n",
    "joblib.dump(model_cause, '/Users/deepu/Desktop/Mini_Project/cause_prediction_model.pkl')\n",
    "\n",
    "print(\"Models trained and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0c52c244-d730-4cca-9e6b-fc4a407c2ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Risk Level    0\n",
      "Location      5\n",
      "dtype: int64\n",
      "Updated 'Location' Column:\n",
      "0    Sector A\n",
      "1    Sector B\n",
      "2    Sector C\n",
      "3    Sector D\n",
      "4    Sector E\n",
      "Name: Location, dtype: object\n",
      "Categorical Columns Data:\n",
      "  Risk Level  Location\n",
      "0       High  Sector A\n",
      "1       High  Sector B\n",
      "2     Medium  Sector C\n",
      "3        Low  Sector D\n",
      "4       High  Sector E\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example DataFrame (replace with your dataset)\n",
    "data = {\n",
    "    'Risk Level': ['High', 'High', 'Medium', 'Low', 'High'],\n",
    "    'Location': [np.nan, np.nan, np.nan, np.nan, np.nan]  # Simulating missing values\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "features = pd.DataFrame(data)\n",
    "\n",
    "# Define the categorical columns\n",
    "categorical_columns = ['Risk Level', 'Location']\n",
    "\n",
    "# Check for missing values in these columns\n",
    "print(\"Missing values per column:\")\n",
    "print(features[categorical_columns].isnull().sum())\n",
    "\n",
    "# Handle missing values in 'Location'\n",
    "if 'Location' in features.columns:\n",
    "    # Convert 'Location' column to string to prevent dtype mismatch warnings\n",
    "    features['Location'] = features['Location'].astype(str)\n",
    "\n",
    "    # Identify rows with missing values (originally NaN, now 'nan')\n",
    "    missing_indices = features['Location'] == 'nan'\n",
    "\n",
    "    # Count missing values\n",
    "    missing_count = missing_indices.sum()\n",
    "\n",
    "    if missing_count > 0:\n",
    "        # Generate alphabetic sector labels\n",
    "        sector_replacements = [f\"Sector {chr(65 + i)}\" for i in range(missing_count)]\n",
    "\n",
    "        # Replace missing values dynamically\n",
    "        features.loc[missing_indices, 'Location'] = sector_replacements\n",
    "\n",
    "    print(\"Updated 'Location' Column:\")\n",
    "    print(features['Location'].head())\n",
    "else:\n",
    "    print(\"'Location' column not found in the dataset!\")\n",
    "\n",
    "# Display the first few rows of categorical columns\n",
    "print(\"Categorical Columns Data:\")\n",
    "print(features[categorical_columns].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
